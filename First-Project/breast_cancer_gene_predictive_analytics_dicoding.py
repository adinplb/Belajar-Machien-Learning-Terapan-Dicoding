# -*- coding: utf-8 -*-
"""Breast_Cancer_Gene_Predictive_Analytics_Dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fvaYw56oT5b3ldeWfYZ1NK1mxlATuYNQ

# **Breast Tumor Prediction and Diagnosis Using Quantitative Cell Nuclear Phenotype Features in Supervised Machine Learning Algorithms**
### Name: Muhammad Adin Palimbani
### Github: [Display Project on Github](https://github.com/adinplb/Belajar-Machien-Learning-Terapan-Dicoding/blob/main/Proyek%20Pertama/README.md)
### Email: madinpalimbani09@gmail.com
### Project Type: First Predictive Analytic Project Report of Applied Machine Learning in Dicoding

## **Import Library**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from google.colab import drive
drive.mount ('/content/drive')

"""## **Import Dataset**"""

df = pd.read_csv('/content/drive/MyDrive/pengembangan-ML-dicoding/Breast Cancer Wisconsin.csv')
df = df.drop(columns=['id', 'Unnamed: 32'])
df['diagnosis']=df['diagnosis'].map({'M':1,'B':0})
df

"""# **Exploratory Data Analysis**




"""

df.info()

print("Jumlah yang terduplikasi:", df.duplicated().sum())

print(df.isna().sum())

df.describe()

"""# **Detect Outliers Using IQR Method**"""

sns.boxplot(x=df['radius_mean'])

sns.boxplot(x=df['texture_mean'])

sns.boxplot(x=df['perimeter_mean'])

sns.boxplot(x=df['area_mean'])

sns.boxplot(x=df['smoothness_mean'])

sns.boxplot(x=df['compactness_mean'])

sns.boxplot(x=df['concavity_mean'])

sns.boxplot(x=df['symmetry_mean'])

sns.boxplot(x=df['fractal_dimension_mean'])

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]

# Check data shape after dropping outliers
df.shape

"""The dataset has been cleaned and has 346 samples

# **Univariate Analysis**
"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""# **Multivariate Analysis**"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""# Evaluasi Korelasi Score"""

plt.figure(figsize=(20, 18))
correlation_matrix = df.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths= 0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

sns.pairplot(df[[ 'radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst']], plot_kws={"s": 3});

from sklearn.decomposition import PCA

pca = PCA(n_components=6, random_state=123)
#Parameter n_components merupakan jumlah komponen atau dimensi, dalam kasus kita jumlahnya ada 3, yaitu 'x', 'y', dan 'z'.
#parameter random_state berfungsi untuk mengontrol random number generator yang digunakan
pca.fit(df[['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst']])
princ_comp = pca.transform(df[['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst']])

pca.explained_variance_ratio_.round(3)

from sklearn.decomposition import PCA
pca = PCA(n_components=1, random_state=123)
pca.fit(df[['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst']])
df['dimension'] = pca.transform(df.loc[:, ('radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst')]).flatten()
df.drop(['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst'], axis=1, inplace=True)

df

df.info()

"""# Train Test Split + SMOTE"""

pip install imbalanced-learn

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# Assuming X contains your features and y contains the corresponding labels
# Perform train-test split

X = df.drop(["diagnosis"],axis =1)
y = df["diagnosis"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE only on the training data
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Now, X_train_resampled and y_train_resampled contain the resampled data using SMOTE,
# while X_test and y_test remain unchanged

# Proceed with model training and evaluation using the resampled training data and the original test data

# Count the number of samples in each class before and after SMOTE
unique_train, counts_train = np.unique(y_train, return_counts=True)
unique_train_resampled, counts_train_resampled = np.unique(y_train_resampled, return_counts=True)

# Create a DataFrame to display the results
data = {
    'Class': unique_train,
    'Original Count': counts_train,
    'Resampled Count': counts_train_resampled
}

df_result = pd.DataFrame(data)
print("Before SMOTE:")
print(df_result)

# Visualize the distribution of classes after SMOTE
print("\nAfter SMOTE:")
print("Classes:", unique_train_resampled)
print("Counts:", counts_train_resampled)

from sklearn.preprocessing import StandardScaler

numerical_features = [
    'texture_mean',
    'smoothness_mean',
    'compactness_mean',
    'concavity_mean',
    'concave points_mean',
    'symmetry_mean',
    'fractal_dimension_mean',
    'radius_se',
    'texture_se',
    'perimeter_se',
    'area_se',
    'smoothness_se',
    'compactness_se',
    'concavity_se',
    'concave points_se',
    'symmetry_se',
    'fractal_dimension_se',
    'texture_worst',
    'smoothness_worst',
    'compactness_worst',
    'concavity_worst',
    'concave points_worst',
    'symmetry_worst',
    'fractal_dimension_worst',
    'dimension',
]
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# Logistic Regression + SMOTE + Confusion Metrics"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler

# Load your dataset
# Assume X contains features and y contains the binary target variable (0 or 1)
#X = ...
#y = ...

# Split the data into training and testing sets
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to balance the training dataset
#smote = SMOTE(random_state=42)
#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Scale features (optional but often recommended)
scaler = StandardScaler()
X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)
X_test_scaled = scaler.transform(X_test)

# Initialize and train logistic regression model before SMOTE
log_reg_before_smote = LogisticRegression()
log_reg_before_smote.fit(X_train, y_train)

# Make predictions on the test set before SMOTE
y_pred_before_smote = log_reg_before_smote.predict(X_test)

# Evaluate performance before SMOTE
print("Performance before SMOTE:")
print(confusion_matrix(y_test, y_pred_before_smote))
print(classification_report(y_test, y_pred_before_smote))




# Initialize and train logistic regression model after SMOTE
log_reg_after_smote = LogisticRegression()
log_reg_after_smote.fit(X_train_resampled_scaled, y_train_resampled)

# Make predictions on the test set after SMOTE
y_pred_after_smote = log_reg_after_smote.predict(X_test_scaled)

# Evaluate performance after SMOTE
print("Performance after SMOTE:")
print(confusion_matrix(y_test, y_pred_after_smote))
print(classification_report(y_test, y_pred_after_smote))



# Compute confusion matrices before and after SMOTE
confusion_matrix_before_smote = confusion_matrix(y_test, y_pred_before_smote)
confusion_matrix_after_smote = confusion_matrix(y_test, y_pred_after_smote)

# Plot confusion matrices
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Plot confusion matrix before SMOTE
axes[0].imshow(confusion_matrix_before_smote, cmap=plt.cm.Blues, interpolation='nearest')
axes[0].set_title('Confusion Matrix Before SMOTE')
axes[0].set_xticks([0, 1])
axes[0].set_yticks([0, 1])
axes[0].set_xlabel('Predicted Label')
axes[0].set_ylabel('True Label')
for i in range(2):
    for j in range(2):
        axes[0].text(j, i, str(confusion_matrix_before_smote[i, j]),
                     horizontalalignment='center', verticalalignment='center', color='white')

# Plot confusion matrix after SMOTE
axes[1].imshow(confusion_matrix_after_smote, cmap=plt.cm.Blues, interpolation='nearest')
axes[1].set_title('Confusion Matrix After SMOTE')
axes[1].set_xticks([0, 1])
axes[1].set_yticks([0, 1])
axes[1].set_xlabel('Predicted Label')
axes[1].set_ylabel('True Label')
for i in range(2):
    for j in range(2):
        axes[1].text(j, i, str(confusion_matrix_after_smote[i, j]),
                     horizontalalignment='center', verticalalignment='center', color='white')

plt.tight_layout()
plt.show()

# Get classification reports before and after SMOTE
classification_report_before_smote = classification_report(y_test, y_pred_before_smote, output_dict=True)
classification_report_after_smote = classification_report(y_test, y_pred_after_smote, output_dict=True)

# Extract accuracy values
accuracy_before_smote = classification_report_before_smote['accuracy']
accuracy_after_smote = classification_report_after_smote['accuracy']

# Plot accuracy before and after SMOTE
labels = ['Before SMOTE', 'After SMOTE']
accuracy_scores = [accuracy_before_smote, accuracy_after_smote]

plt.bar(labels, accuracy_scores, color=['blue', 'green'])
plt.xlabel('SMOTE')
plt.ylabel('Accuracy')
plt.title('Accuracy of Logistic Regression before and after SMOTE')
plt.ylim(0, 1)  # Limit y-axis from 0 to 1 for accuracy range
plt.show()

"""# Neural Network + SMOTE + Confusion Metrics"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load your dataset
# Assume X contains features and y contains the binary target variable (0 or 1)
#X = ...
#y = ...

# Split the data into training and testing sets
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to balance the training dataset
#smote = SMOTE(random_state=42)
#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Scale features (optional but often recommended)
#scaler = StandardScaler()
#X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)
#X_test_scaled = scaler.transform(X_test)

# Define the neural network model architecture before SMOTE
model_before_smote = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model_before_smote.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model before SMOTE
history_original = model_before_smote.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Make predictions on the test set before SMOTE
y_pred_before_smote = (model_before_smote.predict(X_test) > 0.5).astype("int32")

# Compute and print confusion matrix and classification report before SMOTE
print("Confusion Matrix and Classification Report before SMOTE:")
print(confusion_matrix(y_test, y_pred_before_smote))
print(classification_report(y_test, y_pred_before_smote))





# AFTER SMOTE
# Define the neural network model architecture after SMOTE
model_after_smote = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_resampled_scaled.shape[1],)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model_after_smote.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model after SMOTE
history_smote = model_after_smote.fit(X_train_resampled_scaled, y_train_resampled, epochs=10, batch_size=32, verbose=1)

# Make predictions on the test set after SMOTE
y_pred_after_smote = (model_after_smote.predict(X_test_scaled) > 0.5).astype("int32")

# Compute and print confusion matrix and classification report after SMOTE
print("Confusion Matrix and Classification Report after SMOTE:")
print(confusion_matrix(y_test, y_pred_after_smote))
print(classification_report(y_test, y_pred_after_smote))



# Compute confusion matrices before and after SMOTE
confusion_matrix_before_smote = confusion_matrix(y_test, y_pred_before_smote)
confusion_matrix_after_smote = confusion_matrix(y_test, y_pred_after_smote)

# Plot confusion matrices
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Plot confusion matrix before SMOTE
axes[0].imshow(confusion_matrix_before_smote, cmap=plt.cm.Blues, interpolation='nearest')
axes[0].set_title('Confusion Matrix Before SMOTE')
axes[0].set_xticks([0, 1])
axes[0].set_yticks([0, 1])
axes[0].set_xlabel('Predicted Label')
axes[0].set_ylabel('True Label')
for i in range(2):
    for j in range(2):
        axes[0].text(j, i, str(confusion_matrix_before_smote[i, j]),
                     horizontalalignment='center', verticalalignment='center', color='white')

# Plot confusion matrix after SMOTE
axes[1].imshow(confusion_matrix_after_smote, cmap=plt.cm.Blues, interpolation='nearest')
axes[1].set_title('Confusion Matrix After SMOTE')
axes[1].set_xticks([0, 1])
axes[1].set_yticks([0, 1])
axes[1].set_xlabel('Predicted Label')
axes[1].set_ylabel('True Label')
for i in range(2):
    for j in range(2):
        axes[1].text(j, i, str(confusion_matrix_after_smote[i, j]),
                     horizontalalignment='center', verticalalignment='center', color='white')

plt.tight_layout()
plt.show()

# Plot accuracy before and after SMOTE
plt.plot(history_original.history['accuracy'], label='Original Dataset')
plt.plot(history_smote.history['accuracy'], label='After SMOTE')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy of Neural Network before and after SMOTE')
plt.legend()
plt.show()

# Get classification reports before and after SMOTE
classification_report_before_smote = classification_report(y_test, y_pred_before_smote, output_dict=True)
classification_report_after_smote = classification_report(y_test, y_pred_after_smote, output_dict=True)

# Extract accuracy values
accuracy_before_smote = classification_report_before_smote['accuracy']
accuracy_after_smote = classification_report_after_smote['accuracy']

# Plot accuracy before and after SMOTE
labels = ['Before SMOTE', 'After SMOTE']
accuracy_scores = [accuracy_before_smote, accuracy_after_smote]

plt.bar(labels, accuracy_scores, color=['blue', 'green'])
plt.xlabel('SMOTE')
plt.ylabel('Accuracy')
plt.title('Accuracy of NN before and after SMOTE')
plt.ylim(0, 1)  # Limit y-axis from 0 to 1 for accuracy range
plt.show()

"""# Support Vector Machine + SMOTE + Confusion Metrics"""

from sklearn.svm import SVC

# Initialize SVM classifier before SMOTE
svm_classifier_before_smote = SVC(kernel='rbf', random_state=42)

# Train SVM classifier before SMOTE
svm_classifier_before_smote.fit(X_train, y_train)

# Make predictions on the test set before SMOTE
y_pred_before_smote = svm_classifier_before_smote.predict(X_test)

# Compute and print confusion matrix and classification report before SMOTE
print("Confusion Matrix and Classification Report before SMOTE:")
print(confusion_matrix(y_test, y_pred_before_smote))
print(classification_report(y_test, y_pred_before_smote))



#After SMOTE
# Initialize SVM classifier after SMOTE
svm_classifier_after_smote = SVC(kernel='rbf', random_state=42)

# Train SVM classifier after SMOTE
svm_classifier_after_smote.fit(X_train_resampled_scaled, y_train_resampled)

# Make predictions on the test set after SMOTE
y_pred_after_smote = svm_classifier_after_smote.predict(X_test_scaled)

# Compute and print confusion matrix and classification report after SMOTE
print("Confusion Matrix and Classification Report after SMOTE:")
print(confusion_matrix(y_test, y_pred_after_smote))
print(classification_report(y_test, y_pred_after_smote))




# Compute confusion matrices before and after SMOTE
confusion_matrix_before_smote = confusion_matrix(y_test, y_pred_before_smote)
confusion_matrix_after_smote = confusion_matrix(y_test, y_pred_after_smote)

# Get classification reports before and after SMOTE
classification_report_before_smote = classification_report(y_test, y_pred_before_smote, output_dict=True)
classification_report_after_smote = classification_report(y_test, y_pred_after_smote, output_dict=True)

# Extract accuracy values
accuracy_before_smote = classification_report_before_smote['accuracy']
accuracy_after_smote = classification_report_after_smote['accuracy']

# Plot accuracy before and after SMOTE
labels = ['Before SMOTE', 'After SMOTE']
accuracy_scores = [accuracy_before_smote, accuracy_after_smote]

plt.bar(labels, accuracy_scores, color=['blue', 'green'])
plt.xlabel('SMOTE')
plt.ylabel('Accuracy')
plt.title('Accuracy of SVM before and after SMOTE')
plt.ylim(0, 1)  # Limit y-axis from 0 to 1 for accuracy range
plt.show()